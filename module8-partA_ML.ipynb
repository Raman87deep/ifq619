{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - ML, XAI, and data analytics\n",
    "\n",
    "## Machine Learning - Neural Networks Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks are one of the most powerfull techniques in Computer Science. They are computational systems vaguely inspired by the biological neural networks of animal brains.\n",
    "\n",
    "The image shows two neurons connected with each other. In this image, we can identify three important properties:\n",
    "\n",
    "- **Dendrites:** correspond to the input \"wires\" that receive sensory information. Dendrites are the segments of the neuron that receive stimulation in order for the cell to become active. They conduct electrical messages to the neuron cell body for the cell to function\n",
    "\n",
    "- **Axon:** corresponds to the body of the neuron. It is a long slender projection of a nerve cell, or neuron, that conducts electrical impulses away from the neuron's cell body or soma.\n",
    "\n",
    "- **Synapses:** correspond to the output \"wires\". When a nerve impulse reaches the synapse at the end of a neuron, it cannot pass directly to the next one. Instead, it triggers the neuron to release a chemical neurotransmitter. The neurotransmitter drifts across the gap between the two neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./graphics/neuron.png\" width=70% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representations of a Neuron\n",
    "\n",
    "A neuron is a computational unit that with three main layers:\n",
    "\n",
    "- Input Layer\n",
    "\n",
    "- Hidden Layer\n",
    "\n",
    "- Output Layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./graphics/model_NN.png\" width=70% />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember the Machine Learning Process:\n",
    "\n",
    "<img src=\"./graphics/forecast.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ann_visualizer\n",
    "#!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:49:49.429651Z",
     "start_time": "2020-07-05T17:49:49.415946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress TensorFlow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 3 means INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data handling and scientific computing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "\n",
    "# Data visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# Dataset and preprocessing utilities\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics and evaluation tools\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# TensorFlow Keras utilities\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:49:53.010221Z",
     "start_time": "2020-07-05T17:49:53.002089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliary function to plot decision boundaries\n",
    "def plot_decision_boundary(X, y, model, steps=1000, cmap='Paired'):\n",
    "    \"\"\"\n",
    "    Function to plot the decision boundary and data points of a model.\n",
    "    Data points are colored based on their actual label.\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    \n",
    "    # Define region of interest by data limits\n",
    "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    steps = 100\n",
    "    x_span = np.linspace(xmin, xmax, steps)\n",
    "    y_span = np.linspace(ymin, ymax, steps)\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "\n",
    "    # Make predictions across region of interest\n",
    "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Plot decision boundary in region of interest\n",
    "    z = labels.reshape(xx.shape)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "    # Get predicted labels on training data and plot\n",
    "    train_labels = model.predict(X)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Learning Network with ReLu Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In workshop 2B, you had to classify a breast tumour dataset using Naive Bayes algorithm. In this task, you will do classify again the dataset, but using:\n",
    "\n",
    "- (1) a neural network with the 'tanh' as the activation function (you can choose as many hidden layers as you want)\n",
    "- (2) a deep neural network with the 'relu' activation function (you can choose as many hidden layers as you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:49:53.941681Z",
     "start_time": "2020-07-05T17:49:53.930003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's revisit the breast cancer dataset\n",
    "\n",
    "file_path = 'data/breast_data_simple.csv'\n",
    "data = pd.read_csv( file_path )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:51:06.172639Z",
     "start_time": "2020-07-05T17:51:06.168597Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data[[\"radius_mean\", \"texture_mean\"]]\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "n_features = X.columns.to_list()\n",
    "n_outputs = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:49:54.977235Z",
     "start_time": "2020-07-05T17:49:54.758690Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for plotting purposes:\n",
    "# separate the benign tumors (diagnosis = 0) from the malignant ones (diagnosis = 1)\n",
    "malignant = data[ data[ 'diagnosis'] == 1]\n",
    "benign = data[ data[ 'diagnosis'] == 0]\n",
    "\n",
    "# need to convert dataframe into a matrix in order to make the plot work\n",
    "x = X.to_numpy()\n",
    "\n",
    "# plot figure\n",
    "fig=plt.figure(dpi=150)\n",
    "\n",
    "plt.scatter(malignant['radius_mean'], malignant['texture_mean'], c='r', marker='x', s=10, label='malignant')\n",
    "plt.scatter(benign['radius_mean'], benign['texture_mean'], c='b', marker='o', s=10, label='benign')\n",
    "plt.ylabel('texture_mean', fontsize=12)\n",
    "plt.xlabel('radius_mean', fontsize=12)\n",
    "plt.title('Breast Tumors', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:49:55.391210Z",
     "start_time": "2020-07-05T17:49:55.385850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# create numerical encoding for attribute species\n",
    "enc = OneHotEncoder()\n",
    "#Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "Y = enc.fit_transform(y.to_numpy()[:, np.newaxis]).toarray()\n",
    "\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:56:58.904557Z",
     "start_time": "2020-07-05T17:56:58.900028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate the dataset into test set, validation set and train set\n",
    "# YOUR CODE HERE:\n",
    "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3 )\n",
    "# create the training set and the test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state = 42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:57:16.147149Z",
     "start_time": "2020-07-05T17:57:13.349558Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# define the Machine Learning Model: Neural Network\n",
    "# YOUR CODE HERE:\n",
    "model_tum = Sequential()\n",
    "\n",
    "# add the required layers\n",
    "model_tum.add(Dense(10, input_dim= len(n_features), activation='relu'))\n",
    "\n",
    "model_tum.add(Dense(7, activation='relu'))\n",
    "model_tum.add(Dense(5, activation='relu'))\n",
    "model_tum.add(Dense(3, activation='relu'))\n",
    "\n",
    "model_tum.add(Dense(len(n_outputs), activation='softmax'))\n",
    "\n",
    "# compile the network using: \n",
    "# the 'mean_squared_error' as a loss function\n",
    "# the stochastic gradient descent ('sgd') as the optimization function\n",
    "# and the 'accuracy' as evaluation metric\n",
    "# YOUR CODE HERE:\n",
    "model_tum.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model to the data -> learning the model\n",
    "# YOUR CODE HERE:\n",
    "# fit model\n",
    "history = model_tum.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:57:16.578276Z",
     "start_time": "2020-07-05T17:57:16.529323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# evaluate the model\n",
    "_, train_acc = model_tum.evaluate(X_train, Y_train, verbose=1)\n",
    "_, test_acc = model_tum.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:57:17.170987Z",
     "start_time": "2020-07-05T17:57:16.992952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.ylabel('accuracy', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T17:57:17.756417Z",
     "start_time": "2020-07-05T17:57:17.582096Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.ylabel('loss', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
